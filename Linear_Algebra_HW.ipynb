{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhoch123/MAT422/blob/main/Linear_Algebra_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elements of Linear Algebra\n",
        "\n",
        "Authors: Megan Hoch and Bronwyn Curnow\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2TrOcduCkHcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2.1 Linear Spaces"
      ],
      "metadata": {
        "id": "_WoAwQoCkjyg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Combination:** A vector that is the sum of a subset of 2 or more vectors that are multiplied by a constant.\n",
        "\n",
        "**Subspace:** a subspace V is said to be a subset($U⊆V$) if it is closed under both addition ($u_1+u_2∈U$) and multiplication ($αu_1∈U$). 0 is always in the subspace.\n",
        "\n",
        "**Span:** when $w_1,\\ldots,w_m∈V$, the span (span($w_1,\\ldots,w_m$)) is the set of all linear combinations of $w_j$'s.\n",
        "\n",
        "**ColumnSpace:** The columnspace of a matrix A (written as $Col(A)$) is the subspace of $Rᴺ$ spanned by the columms of $A$. The dimension of the columnspace is called the column rank of $A$.\n",
        "\n",
        "**Rowspace:** The rowspace of a matrix $A$ (written as $Row(A)$) is the subspace of $Rᴺ$ spanned by the rows of $A$. The dimension of the rowspace is called the row rank of $A$.\n",
        "\n",
        "**Linear Independence and Dependence:** Vectors are linearly independdent if none of them can be written as a linear combination of the others. Vectors are linearly dependent if they can be written as a combination of each other.\n",
        "\n",
        "**Basis:** The basis of a matrix $A$ (or series of vectors) are the linearly independent vectors that span $A$.\n",
        "\n",
        "**Dimension:** The dimension is the number of vectors required to span a matrix.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LY3xbiy1jsUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import sympy\n",
        "\n",
        "x = np.array(([1,2,3],[4,5,6],[7,8,9]))\n",
        "xrref = sympy.Matrix(x).rref()\n",
        "print(xrref)\n",
        "print('\\n')\n",
        "\n",
        "y = np.array(([5,4,8],[11,2,4],[9,3,8]))\n",
        "yrref = sympy.Matrix(y).rref()\n",
        "print(yrref)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icrSk9sZcvzt",
        "outputId": "03a7ba5a-9117-4215-c167-b1bce50651bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Matrix([\n",
            "[1, 0, -1],\n",
            "[0, 1,  2],\n",
            "[0, 0,  0]]), (0, 1))\n",
            "\n",
            "\n",
            "(Matrix([\n",
            "[1, 0, 0],\n",
            "[0, 1, 0],\n",
            "[0, 0, 1]]), (0, 1, 2))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first matrix's columns are *Linearly Dependent,* since there is a free variable in the third column. The third column could be made with two of the second column minus the first column.\n",
        "\n",
        "The second matrix's columns are *linearly indepdent.* No row could be made with a combination of the others, and the null space has only the trivial solution."
      ],
      "metadata": {
        "id": "q3Ki5Gxjczl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def span(matrix):\n",
        "  rref = sympy.Matrix(matrix).rref()\n",
        "  if len(rref[1]) == 3:\n",
        "    print(matrix.transpose())\n",
        "  else:\n",
        "    a = []\n",
        "    i = 0\n",
        "    while i < 2:\n",
        "      print(matrix[:,rref[1][i]])\n",
        "      i += 1\n",
        "span(x)\n",
        "print('\\n')\n",
        "span(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RLM-ewzdiZc",
        "outputId": "12fb0cc0-7e90-40e9-f6d2-5362e6ff9d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 4 7]\n",
            "[2 5 8]\n",
            "\n",
            "\n",
            "[[ 5 11  9]\n",
            " [ 4  2  3]\n",
            " [ 8  4  8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code shows us the *span* of matrix x and y (or any 3x3 matrix). Since the vectors in x are *linearly dependent,* the third vector does not appear in the span. The columns in y are all *linearly independent,* so it's span contains all three columns."
      ],
      "metadata": {
        "id": "5jAWvTZmd0cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Dimension(matrix):\n",
        "  dim = matrix.shape[1]\n",
        "  print(f'The dimension of this matrix is: {dim}')\n",
        "\n",
        "Dimension(x)\n",
        "Dimension(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdTj3mt7zfr-",
        "outputId": "28050e81-3a3b-4ce9-d7d6-812477de79a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dimension of this matrix is: 3\n",
            "The dimension of this matrix is: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This final example shows the concept of *dimension.* Since both x and y have three columns, they require three vectors to span, and are thus of *dimension* three."
      ],
      "metadata": {
        "id": "tsYz5hjTeiJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2.2 Orthogonality\n"
      ],
      "metadata": {
        "id": "3WMtod8DvZZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Orthonormal:** If the $u_i$’s each have a norm of 1 and are pairwise orthogonal where for all $i$ and all $j\\neq i$, $(u_i, u_j)= 0$ and $ \\parallel u_i \\parallel = 1$.\n",
        "\n",
        "\n",
        "**Best Approximation Theorem:** In a linear subspace $(U \\subseteq V)$ with a vector $(v \\notin U)$  we want to find $v^*$ in $U$ that is closest to $v$ in the norm.\n",
        "\n",
        "**Orthogonal Projection:** A linear subspace $(U \\subseteq V)$ has a orthonormal basis $q_1, \\ldots, q_m$ where the orthogonal projection of $v \\in V$ on $U$ is $P_u v = \\sum_{j=1}^{m} (v,q_j)q_j$.\n",
        "\n",
        "**Projection:** ${\\displaystyle \\operatorname {proj} _{\\mathbf {u} }(\\mathbf {v} )={\\frac {\\langle \\mathbf {u} ,\\mathbf {v} \\rangle }{\\langle \\mathbf {u} ,\\mathbf {u} \\rangle }}{\\mathbf {u} }}$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0g3eqdlCvgwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(yrref)"
      ],
      "metadata": {
        "id": "KQ2nlaPF4elz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, when reduced, this basis of y is *orthonormal*. Each vector is orthogonal to both others, and each vector has a norm of 1."
      ],
      "metadata": {
        "id": "jWXVuk3y4fT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def proj(u,v):\n",
        "  projection = np.dot(u,v)/(np.dot(u,u))*u\n",
        "  return projection\n",
        "\n",
        "print(proj(x[0,:], y[0,:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLii9knq13hc",
        "outputId": "06e08470-011b-4cf2-9358-e8a454cae955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.64285714 5.28571429 7.92857143]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first row of the matrix x *projected* onto the first row of the matrix y."
      ],
      "metadata": {
        "id": "bIeKzFMN6Gdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.2.3 Gram-Schmidt Process\n"
      ],
      "metadata": {
        "id": "aT-GX79O3pSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Gram-Schmidt Process:** This is used to obtain the orthonormal basis of $span(a_1,\\ldots,a_m)$ that is constructed of orthonormal vectors $q_1, \\ldots,q_{i-1}$ , where $a_1, \\ldots, a_m$ is linearly independent in $R^n$.\n"
      ],
      "metadata": {
        "id": "SyXIr6NZ3xUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = np.array(([-6,5,-3],[-3,4,-6],[-6,2,-3]))\n",
        "def Gram_Schmidt(v):\n",
        "  E = v[:,0]/np.linalg.norm(v[:,0])\n",
        "  F = v[:,1]-proj(v[:,0],v[:,1])\n",
        "  G = v[:,2]-proj(v[:,0],v[:,2])-proj(F,v[:,2])\n",
        "  F = F/np.linalg.norm(F)\n",
        "  G = G/np.linalg.norm(G)\n",
        "  return np.array((E,F,G))\n",
        "Gram_Schmidt(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txct2sUq_rjP",
        "outputId": "2d7bf5bf-2836-491c-a4d5-97287ffd8772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.66666667, -0.33333333, -0.66666667],\n",
              "       [ 0.33333333,  0.66666667, -0.66666667],\n",
              "       [ 0.66666667, -0.66666667, -0.33333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows the *Gram-Schmidt* process for a three column matrix (it's easily generalizable to more than three columns, the math behind it is the same, just takes a few more steps of coding). Each vector created is now *orthonormal* to each other."
      ],
      "metadata": {
        "id": "gsXrqXl-evS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.2.4 Eigenvalues and Eigenvectors"
      ],
      "metadata": {
        "id": "M25ZmiIt5Hyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Eigenvalues and Eigenvectors:** Let $A \\in \\mathbb{R}^{d\\times d}$ be a square matrix such that $\\lambda \\in \\mathbb{R}$ is an eigenvalue of $A$ if there exists a non-zero vector $( x \\neq 0)$ where $Ax = \\lambda x$. In this case, the vector $x$ is the eigenvector.\n",
        "\n",
        "**Diagonalization of Symmetric Matrices:** A matrix $A$ is said to be orthogonally diagonalizable  if there is an orthogonal matrix $P$, where $P^{-1} = P^T$, and a diagonal matrix $D$ such that $A=PDP^T = PDP^{-1}$.\n",
        "\n"
      ],
      "metadata": {
        "id": "IO-pzi_K8VLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a=np.array([[1,1],[4,-2]])\n",
        "val,vect = np.linalg.eig(a)\n",
        "\n",
        "print(\"eignevalues: \", val)\n",
        "print(\"eigenvectors: \", vect)"
      ],
      "metadata": {
        "id": "dKkVyLSYDfzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b0919a3-dc53-4919-ac56-4ba797fe324c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eignevalues:  [ 2. -3.]\n",
            "eigenvectors:  [[ 0.70710678 -0.24253563]\n",
            " [ 0.70710678  0.9701425 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code shows how to find the *eigenvalues and eigenvectors* of a matrix."
      ],
      "metadata": {
        "id": "yRbcpd17fMk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = np.array(([6,-6,-12],[-3,3,6],[3,-3,-6]))\n",
        "R = sympy.Matrix(r)\n",
        "P,D = R.diagonalize()\n",
        "print(f'P: {P}')\n",
        "print('\\n')\n",
        "print(f'D: {D}')\n",
        "print('These are the two matrices that make up the diagonalized version of R\\n')\n",
        "print(f'Original: {R}')\n",
        "print(f'Diagonalized: {P*D*P.inv()}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gPrslVhDAZmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e4aec40-2a75-41fb-f87f-188e49f3065c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P: Matrix([[1, 2, 2], [1, 0, -1], [0, 1, 1]])\n",
            "\n",
            "\n",
            "D: Matrix([[0, 0, 0], [0, 0, 0], [0, 0, 3]])\n",
            "These are the two matrices that make up the diagonalized version of R\n",
            "\n",
            "Original: Matrix([[6, -6, -12], [-3, 3, 6], [3, -3, -6]])\n",
            "Diagonalized: Matrix([[6, -6, -12], [-3, 3, 6], [3, -3, -6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Diagonalizing* a matrix allows us to decompose it to two matrices and get our original matrix back. Here we see the two matrices, and the original matrix again by multiplying together $PDP^{-1}$"
      ],
      "metadata": {
        "id": "J7ES6rU-fWuC"
      }
    }
  ]
}